using Microsoft.AspNetCore.Mvc;
using OllamaApi.Attributes;
using OllamaApi.Models;
using Microsoft.Extensions.AI;
using OpenAI;

namespace OllamaApi.Controllers
{
    /// <summary>
    /// This controller provides an endpoint for interacting with OpenAI's chat models. 
    /// It accepts a chat prompt and returns a response generated by the specified OpenAI model. 
    /// The controller is secured with an API key to ensure that only authorized users can access the endpoint.
    /// 
    /// Source: https://learn.microsoft.com/en-us/dotnet/ai/quickstarts/prompt-model?pivots=openai
    /// </summary>

    [ApiKey]
    [ApiController]
    [Route("api/[controller]")]
    public class OpenAIChatController : ControllerBase
    {
        private readonly IChatClient _chatClient;
        private readonly IConfiguration _config;

        public OpenAIChatController(IConfiguration config)
        {
            _config = config;

            string model = _config["OpenAIModelName"] ?? throw new Exception("ModelName missing");
            string key = _config["OpenAIKey"] ?? throw new Exception("OpenAIKey missing");

            _chatClient = new OpenAIClient(key)
                .GetChatClient(model)
                .AsIChatClient();
        }

        [HttpPost]
        public async Task<IActionResult> OpenAIChat([FromBody] ChatRequest request)
        {
            string prompt = $"{request.Prompt}";

            ChatResponse response = await _chatClient.GetResponseAsync(
                prompt,
                new ChatOptions { MaxOutputTokens = 400 });

            return Ok(response);
        }
    }
}